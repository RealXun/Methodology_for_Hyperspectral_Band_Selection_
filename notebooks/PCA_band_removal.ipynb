{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chrisitan\\miniconda3\\envs\\stlit\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Chrisitan\\miniconda3\\envs\\stlit\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\Chrisitan\\miniconda3\\envs\\stlit\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os  # importing the 'os' module to work with the operating system\n",
    "import numpy as np  # importing the 'numpy' library and renaming it to 'np'\n",
    "import scipy  # importing the 'scipy' library for scientific computing\n",
    "from xgboost import XGBClassifier  # importing the XGBoost classifier from the 'xgboost' library\n",
    "import time  # importing the 'time' module to measure time\n",
    "import datetime  # importing the 'datetime' module to work with dates and times\n",
    "import sys  # importing the 'sys' module for system-specific parameters and functions\n",
    "import pandas as pd  # importing the 'pandas' library and renaming it to 'pd'\n",
    "from sklearn.decomposition import PCA  # importing the 'PCA' class from the 'sklearn' library for PCA analysis\n",
    "from sklearn.metrics import accuracy_score  # importing the 'accuracy_score' function from the 'sklearn' library for evaluating classification accuracy\n",
    "from sklearn.model_selection import train_test_split  # importing the 'train_test_split' function from the 'sklearn' library for splitting data into training and testing sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing folder variables\n",
    "main_folder = os.path.abspath(os.path.join(os.pardir))\n",
    "data_folder = (main_folder + \"/\" +\"data\")\n",
    "raw_data = (data_folder + \"/\" + \"raw\")\n",
    "logs_folder = (data_folder + \"/\" + \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pavia_u = scipy.io.loadmat(raw_data + '/' + 'PaviaU.mat')['paviaU']\n",
    "pavia_u_gt = scipy.io.loadmat(raw_data + \"/\" + \"PaviaU_gt.mat\")['paviaU_gt']\n",
    "\n",
    "pavia_c = scipy.io.loadmat(raw_data + '/' + 'Pavia.mat')['pavia']\n",
    "pavia_c_gt = scipy.io.loadmat(raw_data + \"/\" + \"Pavia_gt.mat\")['pavia_gt']\n",
    "\n",
    "salinas = scipy.io.loadmat(raw_data + '/' + 'Salinas.mat')['salinas']\n",
    "salinas_gt = scipy.io.loadmat(raw_data + '/' + 'Salinas_gt.mat')['salinas_gt']\n",
    "\n",
    "indian_pines = scipy.io.loadmat(raw_data + '/' + 'Indian_pines.mat')['indian_pines']\n",
    "indian_pines_gt = scipy.io.loadmat(raw_data + '/' + 'Indian_pines_gt.mat')['indian_pines_gt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('paviaU', (610, 340, 103), 'double')]\n",
      "[('pavia', (1096, 715, 102), 'double')]\n",
      "[('salinas', (512, 217, 224), 'double')]\n",
      "[('indian_pines', (145, 145, 220), 'double')]\n"
     ]
    }
   ],
   "source": [
    "print(scipy.io.whosmat(raw_data + \"/\" + \"PaviaU.mat\"))\n",
    "\n",
    "print(scipy.io.whosmat(raw_data + \"/\" + \"Pavia.mat\"))\n",
    "\n",
    "print(scipy.io.whosmat(raw_data + \"/\" + \"Salinas.mat\"))\n",
    "\n",
    "print(scipy.io.whosmat(raw_data + \"/\" + \"Indian_pines.mat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('paviaU_gt', (610, 340), 'uint8')]\n",
      "[('pavia_gt', (1096, 715), 'uint8')]\n",
      "[('salinas_gt', (512, 217), 'double')]\n",
      "[('indian_pines_gt', (145, 145), 'double')]\n"
     ]
    }
   ],
   "source": [
    "print(scipy.io.whosmat(raw_data + \"/\" + \"PaviaU_gt.mat\"))\n",
    "\n",
    "print(scipy.io.whosmat(raw_data + \"/\" + \"Pavia_gt.mat\"))\n",
    "\n",
    "print(scipy.io.whosmat(raw_data + \"/\" + \"Salinas_gt.mat\"))\n",
    "\n",
    "print(scipy.io.whosmat(raw_data + \"/\" + \"Indian_pines_gt.mat\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA band removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_band_removal(hsi_image, gt, test_size=0.9, random_state=42, var_percentage=0.999):\n",
    "    \n",
    "    # Get the current date and time and format the date as a string in the format \"YYYY-MM-DD\"\n",
    "    now = datetime.datetime.now()\n",
    "    date_str = now.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # get the name of the hsi_image variable\n",
    "    hsi_image_name = [name for name in globals() if globals()[name] is hsi_image][0]\n",
    "\n",
    "    # Check the name of the input hyperspectral image and set the log file name accordingly\n",
    "    if hsi_image_name == 'salinas':\n",
    "        hsi_image_name = 'log'\n",
    "        log_file_name = f\"salinas_{date_str}.txt\"\n",
    "    elif hsi_image_name == 'pavia_u':\n",
    "        hsi_image_name = 'log'\n",
    "        log_file_name = f\"pavia_u_{date_str}.txt\"\n",
    "    elif hsi_image_name == 'pavia_c':\n",
    "        hsi_image_name = 'log'\n",
    "        log_file_name = f\"pavia_c_{date_str}.txt\"\n",
    "    elif hsi_image_name == 'indian_pines':\n",
    "        hsi_image_name = 'log'\n",
    "        log_file_name = f\"indian_pines_{date_str}.txt\"\n",
    "    else:\n",
    "        log_file_name = f\"default_{date_str}.txt\"\n",
    "\n",
    "    # Open the log file in append mode\n",
    "    with open(os.path.join(logs_folder, log_file_name), 'a') as f:\n",
    "        sys.stdout = f\n",
    "        print('\\n', flush=True)\n",
    "        print('--- Log started on {} ---\\n'.format(now.strftime('%Y-%m-%d %H:%M:%S')), flush=True)  \n",
    "\n",
    "        starting_time = time.time() # start the timer to measure the function's execution time\n",
    "        n_samples = hsi_image.shape[0] * hsi_image.shape[1] # get the number of samples in the image\n",
    "        n_bands = hsi_image.shape[2] # get the number of bands in the image\n",
    "        hsi_image_reshaped = hsi_image.reshape(n_samples, n_bands) # reshape the image into a 2D array of samples and bands\n",
    "        print('Reshaping done', flush=True) \n",
    "        print('\\n', flush=True) \n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(hsi_image_reshaped, gt.reshape(-1), stratify=gt.reshape(-1), test_size=test_size, random_state=random_state) # split the reshaped image into training and testing datasets\n",
    "        xgb = XGBClassifier(booster='gbtree', tree_method='hist', objective='multi:softmax', random_state=random_state) # create an XGBoost classifier\n",
    "        xgb.fit(X_train, y_train) # fit the classifier to the training data\n",
    "        feature_importances = xgb.feature_importances_ # get the feature importances from the trained classifier\n",
    "        sorted_indices = np.argsort(feature_importances) # sort the indices of feature importances in ascending order\n",
    "\n",
    "        hsi_image = hsi_image_reshaped.copy() # create a copy of the reshaped image for further processing\n",
    "        original_hsi_image = hsi_image.copy() # create a copy of the original image for reference\n",
    "        indices_deleted = [] # initialize a list to store the band indices that are deleted\n",
    "        round_count = 1 # initialize a variable to keep track of the round number\n",
    "        components = 0 # initialize a variable to store the number of components used in PCA\n",
    "        overall_best_accuracy = 0 # initialize a variable to store the overall best accuracy\n",
    "        deleted_bands_previous_round = None # initialize a variable to store the band indices deleted in the previous round\n",
    "\n",
    "        print(f'Trying PCA with all bands ({hsi_image_reshaped.shape[1]} bands)', flush=True) \n",
    "        pca = PCA(n_components=var_percentage) # create a PCA object with the specified variance percentage\n",
    "        hsi_image_limited = pca.fit_transform(hsi_image) # perform PCA on the reshaped image\n",
    "        X_train, X_test, y_train, y_test = train_test_split(hsi_image_limited, gt.reshape(-1), stratify=gt.reshape(-1), test_size=test_size, random_state=random_state) # split the PCA-transformed data into training and testing datasets\n",
    "        xgb = XGBClassifier(booster='gbtree', tree_method='hist', objective='multi:softmax', random_state=random_state) # create an XGBoost classifier for PCA-transformed data\n",
    "\n",
    "        start_time_fit = time.time() # record the start time of fitting\n",
    "        xgb.fit(X_train, y_train) # fit the classifier to the training data\n",
    "        end_time_fit = time.time() # record the end time of fitting\n",
    "\n",
    "        start_time_pred = time.time() # record the start time of predicting\n",
    "        y_pred = xgb.predict(X_test) # make predictions on the testing data\n",
    "        end_time_pred = time.time() # record the end time of predicting\n",
    "\n",
    "        best_accuracy = accuracy_score(y_test, y_pred) # calculate the accuracy of the predictions\n",
    "        starting_acc = best_accuracy # store the starting accuracy as the best accuracy\n",
    "        print(f'Starting best accuracy: {best_accuracy}. Components: {hsi_image_limited.shape[1]}', flush=True) \n",
    "        print(f'XGBoost fitting time: {end_time_fit - start_time_fit} seconds', flush=True)\n",
    "        print(f'XGBoost prediction time: {end_time_pred - start_time_pred} seconds', flush=True) \n",
    "        print(f'XGBoost total time: {end_time_pred - start_time_fit} seconds', flush=True) \n",
    "        print('-------------------------------------', flush=True) \n",
    "        print('\\n', flush=True) \n",
    "\n",
    "        while best_accuracy > overall_best_accuracy:  # loop until the overall best accuracy is no longer improving\n",
    "            print(f'ROUND {round_count}')  # print the current round number\n",
    "            round_count +=1  # increment the round counter\n",
    "            sorted_indices = [value for value in sorted_indices if value not in indices_deleted]  # remove the indices that were deleted in previous rounds\n",
    "            overall_best_accuracy = best_accuracy  # update the overall best accuracy with the best accuracy from the previous round\n",
    "            best_accuracy = starting_acc  # reset the best accuracy to the starting accuracy\n",
    "            deleted_bands_previous_round = indices_deleted  # record the indices deleted in the previous round\n",
    "            for index in sorted_indices:  # loop through the sorted indices\n",
    "                print(f'Deleted band with index {index} (total bands if this one is deleted: {hsi_image.shape[1]})', flush=True)  # print the index of the deleted band and the total number of bands if this band is deleted\n",
    "                indices_deleted.append(index)  # add the index of the deleted band to the list of deleted indices\n",
    "                hsi_image = np.delete(hsi_image, indices_deleted, axis=1)  # remove the deleted bands from the HSI image\n",
    "                pca = PCA(n_components=var_percentage)  # create a new PCA object with the specified number of components\n",
    "                hsi_image_limited = pca.fit_transform(hsi_image)  # apply PCA to the HSI image\n",
    "                X_train, X_test, y_train, y_test = train_test_split(hsi_image_limited, gt.reshape(-1), stratify=gt.reshape(-1), test_size=test_size, random_state=random_state)  # split the data into training and testing sets\n",
    "                xgb = XGBClassifier(booster='gbtree', tree_method='hist', objective='multi:softmax', random_state=random_state)  # create a new XGBoost classifier\n",
    "\n",
    "                start_time = time.time()  # record the start time of fitting and predicting\n",
    "                xgb.fit(X_train, y_train)  # train the classifier on the training set\n",
    "                fit_time = time.time() - start_time  # calculate the time taken for fitting the classifier\n",
    "\n",
    "                start_time = time.time()  # record the start time of prediction\n",
    "                y_pred = xgb.predict(X_test)  # use the classifier to predict the labels of the test set\n",
    "                predict_time = time.time() - start_time  # calculate the time taken for predicting with the classifier\n",
    "                \n",
    "                acc = accuracy_score(y_test, y_pred)  # calculate the accuracy of the classifier\n",
    "                print(f'Accuracy after deleting band nº{index}: {acc} (total deleted: {len(indices_deleted)} bands)', flush=True)  \n",
    "                print(f'XGBoost fitting time: {fit_time} seconds', flush=True)\n",
    "                print(f'XGBoost prediction time: {predict_time} seconds', flush=True)\n",
    "                print(f'Total XGBoost fitting and prediction time: {fit_time+predict_time} seconds', flush=True)\n",
    "                print('Evaluating results...', flush=True)\n",
    "                print(f'Time elapsed: {time.time() - start_time} seconds', flush=True)  \n",
    "\n",
    "                if best_accuracy > acc:  # if the accuracy is worse than the current best accuracy, undo the deletion of the current band\n",
    "                    indices_deleted.remove(index)\n",
    "                    print(f'The accuracy is worse. Adding back band {index} (total deleted: {len(indices_deleted)} bands)', flush=True)  \n",
    "                    print(f'Current best accuracy: {best_accuracy}. Components: {components}', flush=True)  \n",
    "                else:  # if the accuracy improves, update the best accuracy and record the number of components\n",
    "\n",
    "                    components = hsi_image_limited.shape[1]  # number of components of the PCA\n",
    "                    print(f'The accuracy improves (+{acc - best_accuracy})...', flush=True)  \n",
    "                    print(f'Current best accuracy: {acc}. Components: {components}', flush=True)  \n",
    "                    best_accuracy = acc  # update the best accuracy with the current accuracy\n",
    "                hsi_image = original_hsi_image.copy()  # reset the HSI image to the original image\n",
    "                print(f'Deleted bands up to this point: {indices_deleted}', flush=True)  \n",
    "                print('-------------------------------------', flush=True)  \n",
    "\n",
    "            print(f'Best accuracy this round: {best_accuracy}', flush=True)  \n",
    "            print(f'Improvement over standard PCA: {best_accuracy - starting_acc}', flush=True)  \n",
    "            print(f'Duration of the process: {time.time() - starting_time} seconds' , flush=True)  \n",
    "            print('-------------------------------------', flush=True)  \n",
    "            print('\\n', flush=True)  \n",
    "\n",
    "        print(f'Overall best accuracy: {overall_best_accuracy}', flush=True)  # print the overall best accuracy achieved\n",
    "        print(f'Bands to remove before PCA: {deleted_bands_previous_round}', flush=True)  # print the bands removed before PCA\n",
    "\n",
    "\n",
    "    # Restore stdout to its original state\n",
    "    sys.stdout = sys.__stdout__\n",
    "    \n",
    "    return indices_deleted  # return the list of indices of the deleted bands\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pavia University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_deleted = PCA_band_removal(pavia_u, pavia_u_gt)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pavia Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_deleted = PCA_band_removal(pavia_c, pavia_c_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_deleted = PCA_band_removal(salinas, salinas_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indian Pines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_deleted = PCA_band_removal(indian_pines, indian_pines_gt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
